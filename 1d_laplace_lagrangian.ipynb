{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3c4687d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tikzplotlib\n",
    "import pylab\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import plotly.figure_factory as ff\n",
    "from scipy.spatial import Delaunay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "690282e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model for u\n",
    "u_model = Sequential()\n",
    "u_model.add(Dense(100, input_shape=[1], activation='relu'))\n",
    "u_model.add(Dense(100, activation='relu'))\n",
    "u_model.add(Dense(100, activation='relu'))\n",
    "u_model.add(Dense(100, activation='relu'))\n",
    "u_model.add(Dense(100, activation='relu'))\n",
    "u_model.add(Dense(100, activation='relu'))\n",
    "u_model.add(Dense(1))\n",
    "\n",
    "# Create model for lambda, lambda already defined :(\n",
    "lamda_model = Sequential()\n",
    "lamda_model.add(Dense(100, input_shape=[1], activation='tanh'))\n",
    "lamda_model.add(Dense(100, activation='tanh'))\n",
    "lamda_model.add(Dense(100, activation='tanh'))\n",
    "lamda_model.add(Dense(100, activation='tanh'))\n",
    "lamda_model.add(Dense(100, activation='tanh'))\n",
    "lamda_model.add(Dense(100, activation='tanh'))\n",
    "lamda_model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23afd3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boundary function f(0)=0, f(1)=1\n",
    "def bnd_f(x):\n",
    "    y = np.heaviside(x-1, 1)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e6cf7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# u loss function\n",
    "def u_loss(u_model, lamda_model, x):\n",
    "    with tf.GradientTape() as t:\n",
    "        t.watch(x)\n",
    "        u = u_model(x, training=True)\n",
    "        #print('u = ', u)\n",
    "    du_dx = t.gradient(u,x)\n",
    "    dirichlet_energy = tf.math.reduce_mean(tf.math.square(du_dx))\n",
    "    \n",
    "    mu = 100\n",
    "    bound_loss = mu*(tf.square(u_model(tf.zeros(shape=[1,1]))-bnd_f(0))+tf.square(u_model(tf.ones(shape=[1,1]))-bnd_f(1)))\n",
    "    \n",
    "    # Sample from boundary\n",
    "    lower_bound = tf.zeros(shape=[1,1]) # Lower bound u(0)=0\n",
    "    upper_bound = tf.ones(shape=[1,1]) # Upper bound u(1)=1\n",
    "    bnd_x = tf.transpose(tf.concat([lower_bound, upper_bound], 1))\n",
    "    \n",
    "    u_bnd = u_model(bnd_x)\n",
    "    \n",
    "    lamda = lamda_model(bnd_x,training=False) # x needs to be just on boundary\n",
    "    lagrangian = lamda * (u_bnd - bnd_f(bnd_x))\n",
    "    lagrange_loss = tf.math.reduce_sum(lagrangian)\n",
    "    \n",
    "    loss = dirichlet_energy + lagrange_loss + bound_loss\n",
    "    return loss\n",
    "\n",
    "\n",
    "# lambda loss function\n",
    "def lamda_loss(u_model, lamda_model, x): # x needs to be just on boundary\n",
    "    u_bnd = u_model(x)\n",
    "    \n",
    "    lamda = -1 * lamda_model(x,training=False) # x needs to be just on boundary\n",
    "    lagrangian = lamda * (u_bnd - bnd_f(x))\n",
    "    \n",
    "    loss = tf.math.reduce_sum(lagrangian)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "50765bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_u(epochs):\n",
    "    optimizer = tf.keras.optimizers.Ftrl() # Fancy gradient decent\n",
    "    train_loss_results = [] # For tracking loss during training\n",
    "    iterations_per_epoch = 100\n",
    "    minibatch_size = 100 # Number of points to be selected each iteration\n",
    "\n",
    "    for epoch in range(epochs): \n",
    "        epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "        for iteration in range(iterations_per_epoch):\n",
    "            lower_bound = tf.zeros(shape=[1,1]) # Lower bound u(0)=0\n",
    "            upper_bound = tf.ones(shape=[1,1]) # Upper bound u(1)=1\n",
    "            interior_pts = tf.random.uniform(shape=[1, minibatch_size-2]) # Interior points\n",
    "            x = tf.transpose(tf.concat([lower_bound, interior_pts, upper_bound], 1)) # Actual training data\n",
    "            with tf.GradientTape() as t:\n",
    "                t.watch(x)\n",
    "                #print(x)\n",
    "                #f = u_model(x, training=True) # Estimate for u\n",
    "                loss = u_loss(u_model, lamda_model, x) # Loss\n",
    "            grads = t.gradient(loss, u_model.trainable_weights) # Find model gradients\n",
    "            optimizer.apply_gradients(zip(grads, u_model.trainable_weights)) # Perform gradient decent\n",
    "            epoch_loss_avg.update_state(loss) # Track loss\n",
    "            # End training iteration\n",
    "        train_loss_results.append(epoch_loss_avg.result())\n",
    "        print(\"Epoch {:03d}: Loss: {:.3f}\".format(epoch, epoch_loss_avg.result()))\n",
    "        # End Epoch\n",
    "\n",
    "def train_lamda(epochs):\n",
    "    optimizer = tf.keras.optimizers.Ftrl() # Fancy gradient decent\n",
    "    train_loss_results = [] # For tracking loss during training\n",
    "    iterations_per_epoch = 100\n",
    "    \n",
    "    for epoch in range(epochs): \n",
    "        epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "        for iteration in range(iterations_per_epoch):\n",
    "            lower_bound = tf.zeros(shape=[1,1]) # Lower bound u(0)=0\n",
    "            upper_bound = tf.ones(shape=[1,1]) # Upper bound u(1)=1\n",
    "            x = tf.transpose(tf.concat([lower_bound, upper_bound], 1)) # Actual training data\n",
    "            with tf.GradientTape() as t:\n",
    "                t.watch(x)\n",
    "                #print(x)\n",
    "                #f = u_model(x, training=True) # Estimate for u\n",
    "                loss = lamda_loss(u_model, lamda_model, x) # Loss\n",
    "            grads = t.gradient(loss, lamda_model.trainable_weights) # Find model gradients\n",
    "            optimizer.apply_gradients(zip(grads, lamda_model.trainable_weights)) # Perform gradient decent\n",
    "            epoch_loss_avg.update_state(loss) # Track loss\n",
    "            # End training iteration\n",
    "        train_loss_results.append(epoch_loss_avg.result())\n",
    "        print(\"Epoch {:03d}: Loss: {:.3f}\".format(epoch, epoch_loss_avg.result()))\n",
    "        # End Epoch\n",
    "\n",
    "def training_loop(total_iterations, u_epochs, lamda_epochs):\n",
    "    for i in range(total_iterations):\n",
    "        print(\"Iteration {:03d}:\".format(i))\n",
    "                \n",
    "        print(\"Training u...\")\n",
    "        train_u(u_epochs)\n",
    "        \n",
    "        print(\"Training lambda...\")\n",
    "        train_lamda(lamda_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8fcd24e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 000:\n",
      "Training u...\n",
      "Epoch 000: Loss: 50.204\n",
      "Epoch 001: Loss: 50.102\n",
      "Epoch 002: Loss: 50.061\n",
      "Epoch 003: Loss: 50.038\n",
      "Epoch 004: Loss: 50.024\n",
      "Training lambda...\n",
      "Epoch 000: Loss: -0.000\n",
      "Iteration 001:\n",
      "Training u...\n",
      "Epoch 000: Loss: 50.277\n",
      "Epoch 001: Loss: 50.155\n",
      "Epoch 002: Loss: 50.100\n",
      "Epoch 003: Loss: 50.068\n",
      "Epoch 004: Loss: 50.047\n",
      "Training lambda...\n",
      "Epoch 000: Loss: -0.000\n",
      "Iteration 002:\n",
      "Training u...\n",
      "Epoch 000: Loss: 50.177\n",
      "Epoch 001: Loss: 50.085\n",
      "Epoch 002: Loss: 50.049\n",
      "Epoch 003: Loss: 50.029\n",
      "Epoch 004: Loss: 50.018\n",
      "Training lambda...\n",
      "Epoch 000: Loss: -0.000\n",
      "Iteration 003:\n",
      "Training u...\n",
      "Epoch 000: Loss: 50.363\n",
      "Epoch 001: Loss: 50.219\n",
      "Epoch 002: Loss: 50.150\n",
      "Epoch 003: Loss: 50.107\n",
      "Epoch 004: Loss: 50.079\n",
      "Training lambda...\n",
      "Epoch 000: Loss: -0.000\n",
      "Iteration 004:\n",
      "Training u...\n",
      "Epoch 000: Loss: 50.152\n",
      "Epoch 001: Loss: 50.069\n",
      "Epoch 002: Loss: 50.037\n"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "<built-in function len> returned a result with an error set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib64/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_aggregate_grads\u001b[0;34m(gradients)\u001b[0m\n\u001b[1;32m    639\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.7/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36madd_n\u001b[0;34m(inputs, name)\u001b[0m\n\u001b[1;32m    451\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m--> 452\u001b[0;31m         _ctx, \"AddN\", name, inputs)\n\u001b[0m\u001b[1;32m    453\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib64/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_aggregate_grads\u001b[0;34m(gradients)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemError\u001b[0m: <built-in function len> returned a result with an error set",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib64/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_aggregate_grads\u001b[0;34m(gradients)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemError\u001b[0m: <built-in function len> returned a result with an error set",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib64/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_aggregate_grads\u001b[0;34m(gradients)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemError\u001b[0m: <built-in function len> returned a result with an error set",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib64/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_aggregate_grads\u001b[0;34m(gradients)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemError\u001b[0m: <built-in function len> returned a result with an error set",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib64/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_aggregate_grads\u001b[0;34m(gradients)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemError\u001b[0m: <built-in function len> returned a result with an error set",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib64/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_aggregate_grads\u001b[0;34m(gradients)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemError\u001b[0m: <built-in function len> returned a result with an error set",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib64/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_aggregate_grads\u001b[0;34m(gradients)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemError\u001b[0m: <built-in function len> returned a result with an error set",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib64/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_aggregate_grads\u001b[0;34m(gradients)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemError\u001b[0m: <built-in function len> returned a result with an error set",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib64/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_aggregate_grads\u001b[0;34m(gradients)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemError\u001b[0m: <built-in function len> returned a result with an error set",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-b46f0c597c34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-742b2c24c1e0>\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(total_iterations, u_epochs, lamda_epochs)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training u...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mtrain_u\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training lambda...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-742b2c24c1e0>\u001b[0m in \u001b[0;36mtrain_u\u001b[0;34m(epochs)\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0;31m#f = u_model(x, training=True) # Estimate for u\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlamda_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Find model gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Perform gradient decent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mepoch_loss_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Track loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1078\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1079\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1080\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.7/site-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib64/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_aggregate_grads\u001b[0;34m(gradients)\u001b[0m\n\u001b[1;32m    635\u001b[0m   \u001b[0;32massert\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"No gradients to aggregate\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemError\u001b[0m: <built-in function len> returned a result with an error set"
     ]
    }
   ],
   "source": [
    "training_loop(10,5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "16c6ee94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2494984245300293\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lower_bound = tf.zeros(shape=[1,1]) # Lower bound u(0)=0\n",
    "upper_bound = tf.ones(shape=[1,1]) # Upper bound u(1)=1\n",
    "x = tf.sort(tf.random.uniform(shape=[1,98])) # Interior points\n",
    "test_points_tensor = tf.transpose(tf.concat([lower_bound, x, upper_bound], 1)) # Actual data\n",
    "test_points = test_points_tensor.numpy()\n",
    "u_bar = u_model(test_points_tensor, training=False).numpy()\n",
    "lamda = lamda_model(test_points_tensor, training=False).numpy()\n",
    "f = bnd_f(test_points)\n",
    "x_actual = tf.sort(tf.random.uniform(shape=[1,1000]).numpy()) # Known solution\n",
    "#print(test_points[0])\n",
    "#print(x_actual[0])\n",
    "#print(f[0])\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_title('1D Laplace (Lagrangian Method)')\n",
    "ax.plot(x_actual[0],x_actual[0], label='u(x)', color='blue')\n",
    "ax.plot(test_points, lamda, '*', label='lamda(x)')\n",
    "ax.plot(test_points, u_bar, 'r--', label='u_bar(x)')\n",
    "ax.plot(test_points, f, 'o', label='f(x)')\n",
    "ax.legend()\n",
    "# ax.set_aspect('equal','box')\n",
    "\n",
    "tikzplotlib.save(\"1d_laplace_lagrangian.tex\")\n",
    "\n",
    "average_error = np.sum(abs(u_bar-test_points))/len(u_bar)\n",
    "print(average_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d64b7ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
