{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdc78ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import tikzplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3bd2731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out how partial derivatives and gradients work\n",
    "# def f(x):\n",
    "#     return tf.math.square(x[0]) + tf.math.square(x[1]) + tf.math.multiply(x[0],x[1]) # x^2+y^2+xy\n",
    "#\n",
    "# x_bar = tf.Variable([[1.0,2,3,4],[1,1,1,1]]) # x_bar = (x,y)\n",
    "# print(x[0])\n",
    "# with tf.GradientTape() as t:\n",
    "#     t.watch(x_bar)\n",
    "#     f = f(x_bar)\n",
    "# grad_f = t.gradient(f,x_bar)\n",
    "# df_dx = grad_f[0]\n",
    "# df_dy = grad_f[1]\n",
    "# print(grad_f, df_dx, df_dy)\n",
    "# a = tf.constant([1, 2, 3, 4])\n",
    "# b = tf.constant([1, 1, 1, 1])\n",
    "# d = tf.constant([2,2,2,2])\n",
    "# c = tf.stack([a,b,d])\n",
    "# print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4ec37cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct Model\n",
    "in_bnd_pts_input = Input(shape=(1,2))\n",
    "out_bnd_pts_input = Input(shape=(1,2))\n",
    "int_pts_input = Input(shape=(1,2))\n",
    "\n",
    "w = Dense(10, activation = 'tanh')(in_bnd_pts_input)\n",
    "w = Dense(100, activation = 'tanh')(w)\n",
    "w = Dense(10, activation = 'tanh')(w)\n",
    "w = Dense(1, activation = 'tanh')(w)\n",
    "w = Model(inputs = in_bnd_pts_input, outputs = w)\n",
    "\n",
    "x = Dense(10, activation = 'tanh')(out_bnd_pts_input)\n",
    "x = Dense(100, activation = 'tanh')(x)\n",
    "x = Dense(1, activation = 'tanh')(x)\n",
    "x = Model(inputs = out_bnd_pts_input, outputs = x)\n",
    "\n",
    "y = Dense(10, activation = 'tanh')(int_pts_input)\n",
    "y = Dense(100, activation = 'tanh')(y)\n",
    "y = Dense(10, activation = 'tanh')(y)\n",
    "y = Dense(1, activation = 'tanh')(y)\n",
    "y = Model(inputs = int_pts_input, outputs = y)\n",
    "\n",
    "combined = tf.concat([w.output,x.output,y.output], 0)\n",
    "\n",
    "z = Dense(1, activation = 'linear')(combined)\n",
    "\n",
    "model = Model(inputs = [w.inputs, x.input, y.input], outputs = z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "574b8d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(model, in_bnd_pts, out_bnd_pts, int_pts): # loss_fn(model, inner bound points, outer bound points, interior points)\n",
    "    \n",
    "    r = int_pts[0]\n",
    "    theta = int_pts[1]\n",
    "    print(tf.shape(in_bnd_pts))\n",
    "    print(tf.shape(out_bnd_pts))\n",
    "    print(tf.shape(int_pts))\n",
    "    \n",
    "    with tf.GradientTape() as t:\n",
    "        t.watch(int_pts)\n",
    "        g = model([[in_bnd_pts], [out_bnd_pts], [int_pts]])\n",
    "        #print('g = ', g)\n",
    "    grad_g = t.gradient(g,int_pts) # Not actual gradient, need polar representation!\n",
    "    \n",
    "    dg_dr = grad_g[0] # dg/dr\n",
    "    dg_dtheta = grad_g[1] # dg/dtheta\n",
    "    \n",
    "    grad_g = tf.Variable(dg_dr, tf.math.divide(dg_dtheta, r)) # grad_g = dg/dr r^ + 1/r dg/dtheta theta^.\n",
    "    \n",
    "    dummy_pts = tf.zeros(tf.shape(in_bnd_pts))\n",
    "    \n",
    "    in_bnd_error = model(in_bnd_pts, dummy_pts, dummy_pts, training=False) # g(2,theta)-0\n",
    "    out_bnd_error = tf.subtract(model(dummy_pts, out_bnd_pts, dummy_pts, training=False),tf.math.scalar_mul\n",
    "                                (4,tf.sin(tf.math.scalar_mul(5,out_bnd_pts[1])))) # g(4,theta)-4sin(5theta)\n",
    "    \n",
    "    grad_g_l2_norm = tf.math.scalar_mul(2,tf.nn.l2_loss(grad_g)) # Dirichlet energies\n",
    "    in_bnd_mse = tf.math.scalar_mul(2,tf.nn.l2_loss(in_bnd_error)) # MSE inner bound points\n",
    "    out_bnd_mse = tf.math.scalar_mul(2,tf.nn.l2_loss(out_bnd_error)) # MSE outer bound points\n",
    "\n",
    "    Lambda = 100\n",
    "    \n",
    "    weighted_bnd_loss = tf.math.scalar_mul(Lambda, tf.math.sum(in_bnd_mse,out_bnd_mse)) # weight boundary conditions\n",
    "    \n",
    "    loss = tf.math.sum(grad_g_l2_norm,weighted_bnd_loss)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "813b5caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_for():\n",
    "    # Train network\n",
    "    optimizer = tf.keras.optimizers.Adam() # Fancy gradient decent\n",
    "    epochs = 20\n",
    "    train_loss_results = [] # For tracking loss during training\n",
    "    iterations_per_epoch = 100\n",
    "\n",
    "    in_bnd_pts_size = 1000 # Number of inner boundary points to sample each iteration\n",
    "    out_bnd_pts_size = 1000 # Number of outer boundary points to sample each iteration\n",
    "    int_pts_size = 1000 # Number of interior points to sample each iteration\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "        for iteration in range(iterations_per_epoch):\n",
    "            \n",
    "            r_in_bnd_pts = tf.math.scalar_mul(2,tf.ones([1,in_bnd_pts_size]))\n",
    "            theta_in_bnd_pts = tf.random.uniform([1,in_bnd_pts_size], maxval=2*np.pi)\n",
    "            in_bnd_pts = tf.transpose(tf.stack([r_in_bnd_pts,theta_in_bnd_pts]))\n",
    "            #print(tf.shape(in_bnd_pts)) # Random inner bound points\n",
    "            \n",
    "            r_out_bnd_pts = tf.math.scalar_mul(4,tf.ones([1,out_bnd_pts_size]))\n",
    "            theta_out_bnd_pts = tf.random.uniform([1,out_bnd_pts_size], maxval=2*np.pi)\n",
    "            out_bnd_pts = tf.transpose(tf.stack([r_out_bnd_pts, theta_out_bnd_pts]))\n",
    "            #print(tf.shape(out_bnd_pts)) # Random outer bound points\n",
    "            \n",
    "            r_int_pts = tf.random.uniform([1,int_pts_size], minval=2, maxval=4)\n",
    "            theta_int_pts = tf.random.uniform([1,int_pts_size], maxval = 2*np.pi)\n",
    "            int_pts = tf.transpose(tf.stack([r_int_pts,theta_int_pts]))\n",
    "            #print(tf.shape(int_pts)) # Random interior points\n",
    "            \n",
    "            stacked_inputs = tf.stack([in_bnd_pts, out_bnd_pts, int_pts])\n",
    "            \n",
    "            with tf.GradientTape() as t:\n",
    "                t.watch(stacked_inputs)\n",
    "                #print(x)\n",
    "                #f = model(x, training=True) # Estimate for u\n",
    "                loss = loss_fn(model, in_bnd_pts, out_bnd_pts, int_pts) # Loss\n",
    "            grads = t.gradient(loss, model.trainable_weights) # Find model gradients\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_weights)) # Perform gradient decent\n",
    "            epoch_loss_avg.update_state(loss) # Track loss\n",
    "            # End training iteration\n",
    "        train_loss_results.append(epoch_loss_avg.result())\n",
    "        print(\"Epoch {:03d}: Loss: {:.3f}\".format(epoch, epoch_loss_avg.result()))\n",
    "        # End Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4928e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1000    1    2], shape=(3,), dtype=int32)\n",
      "tf.Tensor([1000    1    2], shape=(3,), dtype=int32)\n",
      "tf.Tensor([1000    1    2], shape=(3,), dtype=int32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-fbdcc331860f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-1a2a139c2c3e>\u001b[0m in \u001b[0;36mtrain_for\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0;31m#print(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0;31m#f = model(x, training=True) # Estimate for u\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_bnd_pts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_bnd_pts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint_pts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Find model gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Perform gradient decent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-5a62e31ee264>\u001b[0m in \u001b[0;36mloss_fn\u001b[0;34m(model, in_bnd_pts, out_bnd_pts, int_pts)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mdg_dtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_g\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# dg/dtheta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mgrad_g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdg_dr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdivide\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdg_dtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# grad_g = dg/dr r^ + 1/r dg/dtheta theta^.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mdummy_pts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_bnd_pts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_variable_v2_call\u001b[0;34m(cls, initial_value, trainable, validate_shape, caching_device, name, variable_def, dtype, import_scope, constraint, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(**kws)\u001b[0m\n\u001b[1;32m    235\u001b[0m                         shape=None):\n\u001b[1;32m    236\u001b[0m     \u001b[0;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m     \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_variable_creator_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator_v2\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m       \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m       shape=shape)\n\u001b[0m\u001b[1;32m   2676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m   1593\u001b[0m           \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m           \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m           distribute_strategy=distribute_strategy)\n\u001b[0m\u001b[1;32m   1596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m   def _init_from_args(self,\n",
      "\u001b[0;32m/usr/local/lib64/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[0;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[1;32m   1691\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The `constraint` argument must be a callable.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1693\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mtrainable\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAINABLE_VARIABLES\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1694\u001b[0m       \u001b[0mcollections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAINABLE_VARIABLES\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1695\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__bool__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__bool__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m   \u001b[0m__nonzero__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__bool__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "train_for()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
